# -*- coding: utf-8 -*-
"""Copy of Pinecone Demo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uda5mNiy_MoSFmDjHsZJuwKlz3JI1WAw

Pinecone: https://www.pinecone.io/
"""

!pip install -q langchain pinecone-client==2.2.4 pypdf sentence-transformers==2.2.2

"""## Extract the Text from the PDF's"""

from langchain.document_loaders import PyPDFDirectoryLoader

loader = PyPDFDirectoryLoader("pdfs")
data = loader.load()

data

"""## Chunkins"""

from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)
text_chunks = text_splitter.split_documents(data)

len(text_chunks)

text_chunks[2]

"""## Embeddings"""

from langchain.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

query_result = embeddings.embed_query("Hello World raj")

query_result

print("Length", len(query_result))

"""## Initializing the Pinecone"""

import os

PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', 'api')
PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'gcp-starter')

import pinecone
# initialize pinecone
pinecone.init(
    api_key=PINECONE_API_KEY,  # find at app.pinecone.io
    environment=PINECONE_API_ENV  # next to api key in console
)
index_name = "testing" # put in the name of your pinecone index here

from langchain.vectorstores import Pinecone

docsearch = Pinecone.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)

"""## If you already have an index, you can load it like this"""

docsearch = Pinecone.from_existing_index(index_name, embeddings)
docsearch

"""## Similarity Search"""

query = "how to hit api in jmeter?"

docs = docsearch.similarity_search(query, k=3)

docs

print(docs)

!pip install huggingface_hub

from langchain import HuggingFaceHub

import os


os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hugging_face_api"

llm= HuggingFaceHub(repo_id='mistralai/Mixtral-8x7B-Instruct-v0.1',model_kwargs={'temperature':1})

from langchain.chains import RetrievalQA

qa = RetrievalQA.from_chain_type(llm=llm, chain_type="stuff", retriever=docsearch.as_retriever())

query = "what is jmeter?"

print(qa.run(query))

